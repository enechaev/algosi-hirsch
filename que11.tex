\let\bf\bfseries
\let\it\itshape
\section{(11) Алгоритмы Прима и Крускала для задачи о минимальном остовном дереве (\groth)}
\begin{definition}
	Для связного графа $G=\langle V,E\rangle$ {\bf остовным деревом} называется подграф $G'=\langle V,E'\rangle,E'\subseteq E$, который является деревом.
\end{definition}
\begin{problem*}
	В связном взвешенном неориентированном графе $G=\langle V,E\rangle$ с весовой функцией $w\colon E\to\mathbb{R}$ найти остовное дерево минимального веса.
\end{problem*}
Вспомним, что подмножества ребер графа, в которых нет циклов, являются независимыми в {\it цикловом матроиде}. Наша задача превращается в поиск базы минимального веса, для которого можно использовать {\it жадный алгоритм}\footnote{в курсе комбинаторики был поиск множества максимального веса, но это, по большому счету, одно и то же, потому что можно инвертировать все веса}: начиная с пустого множества последовательно добавляем ребра минимального веса, пока можем.

Алгоритмы Прима и Крускала являются реализациями этого подхода. Остается только научиться быстро находить ребро минимального веса, который можно добавить, чтобы множество осталось независимым.
\begin{definition}
	{\bf\it Разрезом} графа $G=\langle V,E\rangle$ называется такая пара $(S,T)$ подмножеств $V$, что $V=S\sqcup T$. Ребро называется {\bf\it пересекающим разрез}, если концы ребра находятся в разных множествах разреза. Разрез называется {\bf\it согласованным} со множеством $A \subseteq E$, если никакое ребро из $A$ не пересекает разрез. Ребро называется {\bf легким}, если оно пересекает разрез и имеет минимальный вес среди всех таких ребер, пересекающих разрез.
\end{definition}
\begin{theorem}
	В графе $G=\langle V,E\rangle$ с весовой функцией $w$ $A\subseteq E$~-- независимое подмножество, согласованое с разрезом $(S,T)$, ребро $(u,v)$~-- легкое. Тогда $A\cup\{(u,v)\}$~-- подмножество базы минимального веса, содержащего $A$.
\end{theorem}
\begin{proof}
	Понятно, что множество будет независимым: если это не так, то еще какое-то ребро пересекает разрез.

	Пусть $M$~-- база минимального веса среди всех баз, содержащих $A\cup\{(u,v)\}$, Докажем, что она имеет минимальный вес среди всех баз, содержащих $A$. Пусть $M'$~-- другая база минимального веса, содержащая $A$. Если она не содержит $(u,v)$, то она содержит какое-то другое ребро $(x,y)$, пересекающее разрез, но тогда $w(M')=w(M)-w((u,v))+w((x,y))\ge w(M)$. Но также по определению $M$, $M'$: $w(M')\le w(M)\Rightarrow w(M')=w(M)$.
\end{proof}
\begin{corollary}\label{cor}
	$G=\langle V,E\rangle,w$~--- неориентированный взвешенный связный граф. $A\subseteq E$~-- независимое множество в его цикловом матроиде. $C=\langle V_C,E_C\rangle$~-- компонента связности леса $G_A=\langle V,A\rangle$. Если $(u,v)$~-- легкое ребро, которое соединяет $C$ с другой компонентой связности, то $A\cup\{u,v\}$~--- подмножество базы минимального веса, содержащего $A$.
\end{corollary}
\begin{proof}
	Разрез $(V_C,V\smallsetminus V_C)$ согласован с $A$ и $(u,v)$ его пересекает.
\end{proof}
\subsection{Алгоритм Крускала}
Этот алгоритм использует структуру данных, которая называется
\subsubsection[Система неперескающихся множеств]{
    Система непересекающихся множеств
    \protect\footnote{
        Предупреждение: присутствует частичный намеренный копипаст \href{https://e-maxx.ru/algo/dsu}{отсюда} и \href{https://biblio.mccme.ru/node/5623}{из этой книги}.
    }
}

Эта структура данных предоставляет следующие возможности. Изначально имеется несколько элементов, каждый из которых находится в отдельном (своём собственном) множестве. За одну операцию можно объединить два каких-либо множества, а также можно запросить, в каком множестве сейчас находится указанный элемент. Также, в классическом варианте, вводится ещё одна операция — создание нового элемента, который помещается в отдельное множество.

Таким образом, над этой структурой можно реализовать три операции:

\begin{itemize}
	\item {\tt make\_set}$(x)$~-- добавляет новый элемент x, помещая его в новое множество, состоящее из одного него.
	\item {\tt union\_sets}$(x,y)$~-- объединяет два указанных множества (множество, в котором находится элемент x, и множество, в котором находится элемент y).
	\item {\tt find\_set}$(x)$~-- возвращает, в каком множестве находится указанный элемент x. На самом деле при этом возвращается один из элементов множества (называемый представителем или лидером (в англоязычной литературе "leader")). Этот представитель выбирается в каждом множестве самой структурой данных (и может меняться с течением времени, а именно, после вызовов {\tt union\_sets}$()$).
\end{itemize}

Например, если вызов {\tt find\_set}() для каких-то двух элементов вернул одно и то же значение, то это означает, что эти элементы находятся в одном и том же множестве, а в противном случае — в разных множествах.

Мы будем пользоваться не самой эффективной реализацией, но ее хватит для хорошей оценки на алгоритм Крускала.

\begin{algodescription}{Реализация: лес непересекающихся множеств}
    Для каждого множества $X$ из разбиения построим некоторое направленное дерево $T_X$, вершины которого будут отвечать элементам множества $X$. Для элемента $x$ его родителя обозначим $p(x)$ (если $x$~-- корень, то $p(x) = {\tt nil}$).

    Ясно, что ответ на запрос {\tt find\_set}$(x)$ находится просто переходом по ссылкам $x \mapsto p(x)$, пока не упремся в {\tt nil}. Операция {\tt make\_set}$(x)$ совсем тривиальна~-- просто инициализируем $p(x) := {\tt nil}$.

    Операция {\tt union\_sets}$(x, y)$ выполняется следующим образом: вначале мы находим корни соответствующих поддеревьев $x'$ и $y'$ (выполняя запросы {\tt find\_set}). В случае, если $x' = y'$, элементы $x$ и $y$ уже содержатся в одном подмножестве, так что никакие дополнительные действия не требуются. Иначе мы должны объединить деревья $T_X$ и $T_Y$~-- добавим дугу между корнями поддеревьев $x'$ и $y'$ так, чтобы <<меньшее>> дерево было подключено к <<большему>>.

    В каком смысле <<большее>> или <<меньшее>>? Здесь сравнение деревьев идет по их высоте, т.е. длине максимального пути от корня до листа. Как это реализовать? Высоту поддерева с корнем $x$ мы обозначим $r(x)$ и будем хранить вместе с значением $p(x)$ для каждой вершины $x$. Тогда если $r(x') \neq r(y')$, то пусть НУО $r(x') < r(y')$, тогда присваиваем $p(x') := y'$, не изменяя при этом $r$ ни у каких вершин~-- ведь никакие высоты поддеревьев не изменились. Если же $r(x') = r(y')$, то неважно, какое дерево к какому присоединять, так что присвоим $p(x') := y'$. При этом высота дерева $T_Y$ увеличилась на 1, так что присвоим $r(y') := r(y') + 1$.
\end{algodescription}

Время работы ${\tt make\_set}$, конечно, $O(1)$. Интерес представляет операция {\tt find\_set}$(x)$. Ее время работы, очевидно, пропорционально высоте дерева, к которому принадлежит вершина $x$. А операция {\tt union\_sets} лишь два раза вызывает {\tt find\_set}, после чего совершает $O(1)$ операций. Так что в оценке времени работы этих двух операций нам поможет следующая лемма.

\begin{lemma*}
    Поддерево с корнем $x$ содержит не менее $2^{r(x)}$ вершин.
\end{lemma*}
\begin{proof}
    Индукция по числу вершин в поддереве. База~-- поддерево из одной вешины $\{z\}$, в котором $1 = 2^r(z)$ вершин.

    Переход: пусть данное дерево $T$ было получено присоединением корня $x \in T_X$ к корню $y \in T_Y$. Обозначим $r_0(x)$, $r_0(y)$ высоты соответствующих поддеревьев до присоединения, $r(y)$~-- высота получившегося дерева. По индукционному предположению $|T_X| \geq 2^{r_0(x)}$, $|T_Y| \geq 2^{r_0(y)}$, так что $|T| \geq 2^{r_0(x)} + 2^{r_0(y)}$.

    Возможны два случая: $r_0(x) < r_0(y)$ или $r_0(x) = r_0(y)$. В первом случае никакие $r$ не меняются, так что $r(y) = r_0(y)$. В этом случае $|T| \geq 2^{r_0(y)} = 2^{r(y)}$, что доказывает переход. Во втором случае $r(y) = r_0(y) + 1$, но $|T| \geq 2^{r_0(y)} + 2^{r_0(y)} = 2^{r_0(y) + 1} = 2^{r(y)}$, что доказывает переход.
\end{proof}

Мы получаем, что высота дерева на $n$ вершинах не превосходит $O(\log n)$, значит такое же и время работы операций {\tt find\_set} и {\tt union\_sets}.

\begin{nb*}
    Существуют хорошо известные и намного более эффективные реализации. Можно почитать о них \href{https://e-maxx.ru/algo/dsu}{здесь}.
\end{nb*}

\subsubsection{Сам алгоритм Крускала}
\begin{algorithm}[H]
	\DontPrintSemicolon
	\SetKwIF{If}{ElseIf}{Else}{if}{:}{elif}{else}{end}
	\SetKwFor{ForEach}{foreach}{:}{}
	\SetKwFunction{KruskalMST}{Kruskal-MST}
	\SetKwFunction{makeset}{make\_set}
	\SetKwFunction{find}{find\_set}
	\SetKwFunction{union}{union\_sets}
	\SetKwFunction{sort}{Sort}
	\SetKwProg{Fn}{}{:}{}
	\Fn{\KruskalMST{$G=\langle V,E\rangle$, $w$}}{
		$A=\varnothing$\;
		\ForEach{$x\in V$}{\label{alg:init-begin}
			\makeset{$x$}\;\label{alg:init-end}
		}
		\sort{$E$, $\lambda x\lambda y.[w(x)<w(y)]$} \label{alg:sort}\tcp*{т.е. сортим $E$ по возрастанию весов}
		\ForEach{$(u,v)\in E$}{\label{alg:cycle-begin}
			\If{\find{$u$} $\ne$ \find{$v$}}{\label{alg:ops-begin}
				$A$ := $A\cup\{(u,v)\}$\;
				\union{$(u,v)$}\;\label{alg:cycle-end}
			}
		}
	}
\end{algorithm}
Это прямо в буквальном смысле реализация жадного алгоритма, поэтому его корректность очевидна.

Оценка времени зависит от времени работы операций СНМ и времени сортировки. Так, при нашей реализации СНМ и сортировке {\tt QuickSort} получаем вот что.
\begin{itemize}
    \item Цикл на строчках~\ref{alg:init-begin}-\ref{alg:init-end} выполняется за $O(|V|)$.
    \item Сортировка на строке~\ref{alg:sort} выполняется за $O(|E| \log |E|)$.
    \item Строки~\ref{alg:ops-begin}-\ref{alg:cycle-end} включают две операции {\tt find\_set} и одну операцию {\tt union\_sets}, плюс еще $O(1)$ операций, а всё это выполняется за $O(\log |V|)$.
    \item А собственно цикл~\ref{alg:cycle-begin}-\ref{alg:cycle-end} тогда выполняется за $O(|E| \log |V|)$.
\end{itemize}
Общее время работы~--- $O(|V| + |E|\log|V|)$, а так как в связном графе $|V| \leq |E|+1$, это можно записать как $O(|E|\log|V|)$.

\subsection{Алгоритм Прима}
Это тоже вариант жадного алгоритма. Он похож на алгоритм Дейкстры, в частности, использует {\it очередь с приоритетами} (min-heap, она была у Охотина в  \href{https://users.math-cs.spbu.ru/~okhotin/teaching/algorithms_2019/okhotin_algorithms_2019_l4.pdf}{лекции 4}, а описание реализации с помощью кучи в \href{https://users.math-cs.spbu.ru/~okhotin/teaching/algorithms_2019/okhotin_algorithms_2019_l5.pdf}{лекции 5}).

Этот алгоритм находит остовное дерево, строя его из корня $r\in V$. К каждой вершине $u\in V$ добавим два атрибута: key~-- длина наименьшего ребра, которым эту вершину можно соединить с остовным деревом и $\pi$~-- вершина из дерева, с которой $u$ соединена ребром, описанным в атрибуте key. По атрибуту key устанавливается приоритет вершины в очереди $Q$.

\newcommand{\nil}{\scshape nil}
\begin{algorithm}
	\DontPrintSemicolon
	\SetKwIF{If}{ElseIf}{Else}{if}{:}{elif}{else}{end}
	\SetKwFor{While}{while}{:}{}
	\SetKwFor{ForEach}{foreach}{:}{}
	\SetKwFunction{PrimMST}{Prim-MST}
	\SetKwFunction{extractmin}{extract-min}
	\SetKwFunction{decreasekey}{decrease-key}
	\SetKwFunction{queue}{Queue}
	\SetKwProg{Fn}{}{:}{}
	\Fn{\PrimMST{$G=\langle V,E\rangle$, $w$, $r\in V$}}{
		\ForEach{$u\in V$}{\label{alg-prim:init-begin}
			$u$.key := $\infty$\;
			$u$.$\pi$ := \nil\;
		}
		$r$.key := $0$\;
		$Q$ := \queue{$V$}\;\label{alg-prim:init-end}

		\While{$Q\ne\varnothing$}{
			$u$ := \extractmin{$Q$}\;
			\ForEach{$v\in\{x|(u,x)\in E\}$}{
				\If{$v\in Q$ {\normalfont\bfseries and} $w(u,v)<v$.{\normalfont key}}{
					$v$.$\pi$ := $u$\;
					$v$.\decreasekey{$w(u,v)$}\;
				}
			}
		}
	}
\end{algorithm}
Алгоритм неявно строит независимое множество $A$ в виде $A=\{(v,v.\pi)|v\in V\smallsetminus\left(Q\cup\{r\}\right)\}$. Разрезом тут является пара $(Q,V\smallsetminus Q)$, добавляются только легкие ребра, поэтому (из следствия~\ref{cor}) алгоритм корректен.

Оценка времени зависит от варианта реализации очереди с приоритетами. При использовании двоичной кучи строки \ref{alg-prim:init-begin}-\ref{alg-prim:init-end} выполняются за время $O(|V|)$. Цикл {\tt\bf while} выполняется $O(|V|)$ раз. Операция \texttt{extract-min} выполняется за $O(\log |V|)$  раз, а внутренний цикл {\tt\bf foreach} всего выполняется $O(|E|)$ раз (так как общая длина всех списков смежности $2|E|$: каждую ребро посчитано дважды). Операция \texttt{decrease-key} реализуется за $O(\log|V|)$, поэтому общее время работы $O(|V|+|V|\log|V|+|E|\log|V|)=O(|E|\log|V|)$.
